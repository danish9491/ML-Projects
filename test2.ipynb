{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch numpy pandas matplotlib scikit-learn torchvision Pillow\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall sklearn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip show scikit-learn\n",
    "\n",
    "# !pip install scikit-learn\n",
    "# !pip install --user scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory paths\n",
    "train_dir = r\"D:\\College Notes\\5th Sem\\CS307 Machine Learning 4\\Bone_Fracture_Binary_Classification\\train\"\n",
    "val_dir = r\"D:\\College Notes\\5th Sem\\CS307 Machine Learning 4\\Bone_Fracture_Binary_Classification\\val\"\n",
    "test_dir = r\"D:\\College Notes\\5th Sem\\CS307 Machine Learning 4\\Bone_Fracture_Binary_Classification\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'D:/College Notes/5th Sem/CS307 Machine Learning 4/Bone_Fracture_Binary_Classification/val/fractured'\n",
    "\n",
    "image_files = [f for f in os.listdir(folder_path) if f.endswith('.jpg')]\n",
    "image_files = image_files[:5]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 5))\n",
    "\n",
    "for i, image_file in enumerate(image_files):\n",
    "    img_path = os.path.join(folder_path, image_file)  # Full path to the image\n",
    "    img = Image.open(img_path)                       \n",
    "    axes[i].imshow(img)                              \n",
    "    axes[i].axis('off')                              \n",
    "    axes[i].set_title(f\"Image {i+1}\")                \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms  # For data transformations\n",
    "# Dictionary containing transformation pipelines for training and validation data\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),                           # Convert image to tensor\n",
    "        transforms.CenterCrop(400),                      # Crop the center of the image to size 400x400\n",
    "        transforms.RandomHorizontalFlip(),               # Randomly flip the image horizontally with a probability of 50%\n",
    "        transforms.Grayscale(num_output_channels=1)]),   # Convert the image to grayscale with a single channel\n",
    "\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),                           # Convert image to tensor\n",
    "        transforms.CenterCrop(400),                      # Crop the center of the image to size 400x400\n",
    "        transforms.Grayscale(num_output_channels=1)])   # Convert the image to grayscale with a single channel for validation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data points (training examples)\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the directory path to the original dataset\n",
    "original_dataset_dir = r\"D:\\College Notes\\5th Sem\\CS307 Machine Learning 4\\Bone_Fracture_Binary_Classification\\train\"\n",
    "\n",
    "# Listing the classes (subdirectories) in the original dataset directory\n",
    "classes = os.listdir(original_dataset_dir)\n",
    "\n",
    "# Printing the number of classes and the list of classes\n",
    "print(len(classes))  \n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=data_transforms['val'])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Check the size of the datasets\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # Grayscale input\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 50 * 50, 256)  # Adjust based on image size after pooling\n",
    "        self.fc2 = nn.Linear(256, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 50 * 50)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))  # Use sigmoid for binary classification\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "\n",
    "# Allow loading of truncated images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the model, define loss function and optimizer\n",
    "model = CustomCNN().to(device)\n",
    "criterion = nn.BCELoss()  # For binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.view(-1), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.float().to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs.view(-1), labels)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "# Train the model+\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
