{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from PIL import ImageFile\n",
    "\n",
    "# Ensure truncated images can load\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Set device for GPU usage if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Directories for train, validation, and test sets\n",
    "train_dir = r\"D:\\College Notes\\5th Sem\\CS307 Machine Learning 4\\Bone_Fracture_Binary_Classification\\train\"\n",
    "val_dir = r\"D:\\College Notes\\5th Sem\\CS307 Machine Learning 4\\Bone_Fracture_Binary_Classification\\val\"\n",
    "test_dir = r\"D:\\College Notes\\5th Sem\\CS307 Machine Learning 4\\Bone_Fracture_Binary_Classification\\test\"\n",
    "\n",
    "# Step 1: Define Data Augmentation and Normalization\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Datasets with Data Augmentation\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(root=val_dir, transform=data_transforms['val'])\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=data_transforms['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Handle Class Imbalance with Weighted Sampling\n",
    "class_counts = [len(np.where(np.array(train_dataset.targets) == t)[0]) for t in range(len(train_dataset.classes))]\n",
    "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
    "sample_weights = [class_weights[t] for t in train_dataset.targets]\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Step 4: Define DataLoaders with Weighted Sampling for Training Data\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\daans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Load Pretrained Model (e.g., ResNet50) and Customize for Binary Classification\n",
    "model = models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers initially\n",
    "\n",
    "# Modify the classifier head for binary classification\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, 1)  # Binary classification\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Step 6: Set Up Loss Function with Class Weights, Optimizer, and Learning Rate Scheduler\n",
    "# Apply higher weight to the minority class\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([class_weights[0] / class_weights[1]]).to(device))\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=1e-4)  # Only fine-tuning the last layer initially\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "# Step 7: Define Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, delta=0):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "# Instantiate early stopping\n",
    "early_stopping = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Training Function with Early Stopping and Scheduler\n",
    "def train_model_with_early_stopping(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.float().unsqueeze(1).to(device)  # Reshape for binary loss\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss / len(train_loader):.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Step the scheduler and check early stopping\n",
    "        scheduler.step(val_loss)\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\daans\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.5888, Val Loss: 0.4966\n",
      "Epoch [2/10], Train Loss: 0.4871, Val Loss: 0.4535\n",
      "Epoch [3/10], Train Loss: 0.4718, Val Loss: 0.4510\n",
      "Epoch [4/10], Train Loss: 0.4288, Val Loss: 0.4223\n",
      "Epoch [5/10], Train Loss: 0.4137, Val Loss: 0.4501\n",
      "Epoch [6/10], Train Loss: 0.3976, Val Loss: 0.4370\n",
      "Epoch [7/10], Train Loss: 0.3698, Val Loss: 0.4403\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Train the Model\n",
    "train_model_with_early_stopping(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    fractured       0.73      0.83      0.78       238\n",
      "not fractured       0.83      0.73      0.78       268\n",
      "\n",
      "     accuracy                           0.78       506\n",
      "    macro avg       0.78      0.78      0.78       506\n",
      " weighted avg       0.78      0.78      0.78       506\n",
      "\n",
      "Confusion Matrix:\n",
      "[[198  40]\n",
      " [ 72 196]]\n",
      "AUC-ROC Score: 0.7816\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Evaluate Model on Test Data\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()  # Threshold for binary output\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    print(classification_report(all_labels, all_preds, target_names=['fractured', 'not fractured']))\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    auc_score = roc_auc_score(all_labels, all_preds)\n",
    "    print(f\"AUC-ROC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluate_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
